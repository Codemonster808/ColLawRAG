# Known Issues - ColLawRAG

## üêõ Bug #1: Ollama Judge Timeouts (2026-02-27)

**S√≠ntoma:**
- Juez Ollama (`qwen2.5:7b-instruct` y `qwen2.5:14b-instruct`) da timeout constante (>150s) al evaluar respuestas
- 80-90% de evaluaciones fallan con "The operation was aborted due to timeout"
- Bloquea completamente los benchmarks

**Causa ra√≠z:**
- Ollama local tiene latencia extremadamente alta e inconsistente
- qwen2.5:14b requiere 9.8 GiB RAM (solo hay 6-7 GiB disponibles)
- qwen2.5:7b es m√°s lento de lo esperado para evaluaciones cortas

**Impacto:**
- Sprint 1 bloqueado (S1.7, S1.9, S1.10)
- Benchmarks tardan 2-3 horas en vez de 10-15 minutos
- Datos incompletos (solo 1-2 casos de 30 evaluados correctamente)

**Soluci√≥n temporal:**
- Usar Groq como juez (llama-3.1-8b-instant: 560 tps, $0.05/$0.08)
- Configurar timeout m√°s largo (300s) solo si es absolutamente necesario

**Soluci√≥n permanente:**
- Migrar juez a API externa confiable (Groq, OpenRouter, o HuggingFace Inference)
- Nunca usar Ollama local para benchmarks cr√≠ticos
- Documentar modelos compatibles con RAM disponible

**Workaround para benchmarks:**
```bash
# Usar Groq como juez (r√°pido y confiable)
JUDGE_PROVIDER=groq JUDGE_MODEL=llama-3.1-8b-instant node scripts/evaluate-accuracy.mjs --limit 30
```

**Historia:**
- 2026-02-27 08:00: Primer timeout detectado con qwen2.5:14b (RAM insuficiente)
- 2026-02-27 17:00: Segundo timeout con qwen2.5:7b (latencia alta)
- 2026-02-27 22:00: Bug documentado y soluci√≥n implementada

---

## üêõ Bug #2: Producci√≥n 404 Error con Embeddings HF API (2026-03-01)

**S√≠ntoma:**
```json
{
  "error": "Error interno",
  "message": "CRITICAL: Hugging Face embeddings failed in production. HF API error: 404 - Not Found"
}
```

**Causa ra√≠z:**
- Modelo `Xenova/paraphrase-multilingual-MiniLM-L12-v2` es para uso local (transformers.js)
- NO funciona con HF API endpoint (`router.huggingface.co`)
- C√≥digo asum√≠a `EMB_PROVIDER=hf` por defecto, incluso para modelos Xenova

**Impacto:**
- Producci√≥n Vercel completamente rota despu√©s de deploy Sprint 3
- Todas las queries RAG fallan con 500 error
- Sistema inutilizable hasta fix

**Soluci√≥n:**
Auto-detectar provider bas√°ndose en nombre del modelo:
```typescript
// lib/embeddings.ts
const EMB_PROVIDER = process.env.EMB_PROVIDER || 
  (EMBEDDING_MODEL.startsWith('Xenova/') ? 'xenova' : 'hf')
```

**Fix aplicado:**
- Commit `1eec05d` - "Auto-detect Xenova provider to fix production 404 error"
- Deployado a producci√≥n: 2026-03-01 13:33
- Status: ‚úÖ **RESUELTO**

**Workaround manual:**
```bash
# En Vercel, configurar variable de entorno:
EMB_PROVIDER=xenova
```

**Historia:**
- 2026-03-01 13:25: Deploy Sprint 3 a producci√≥n
- 2026-03-01 13:30: Primera detecci√≥n error 404 en health check
- 2026-03-01 13:32: Fix implementado (auto-detect)
- 2026-03-01 13:33: Fix deployado y verificado

---

## üêõ Bug #3: Benchmark Local Bloqueado por RAM Insuficiente (2026-03-01)

**S√≠ntoma:**
- Ollama runner: 5GB RAM consumidos, 384% CPU (thrashing)
- RAG queries locales: 8+ minutos por timeout/swap
- Sistema completamente no responsivo durante benchmarks

**Causa ra√≠z:**
- JUDGE_MODEL `qwen2.5:14b-instruct` requiere 9.8GB RAM
- Sistema solo tiene 15GB total, 6-7GB disponibles
- Ollama carga modelo en RAM completo antes de responder

**Impacto:**
- Benchmarks locales imposibles de ejecutar
- Validaci√≥n de Sprint 3 bloqueada
- Desarrollo local severamente limitado

**Soluci√≥n temporal:**
1. Cambiar JUDGE_MODEL de 14b a 7b en `.env.local`:
   ```bash
   JUDGE_MODEL=qwen2.5:7b-instruct
   ```
2. Ejecutar benchmarks contra **producci√≥n Vercel** en lugar de local
3. Usar Groq para evaluaciones cr√≠ticas (ver Bug #1)

**Soluci√≥n permanente (pendiente):**
- Migrar juez a API externa (Groq, OpenRouter)
- O: Actualizar RAM del sistema a 32GB+
- O: Usar Docker con l√≠mites de memoria para Ollama

**Status:** ‚ö†Ô∏è **WORKAROUND ACTIVO** (pendiente soluci√≥n permanente)

**Historia:**
- 2026-03-01 11:00: Primera detecci√≥n (benchmark LAB-001 timeout >8 min)
- 2026-03-01 11:54: Cambio a qwen2.5:7b
- 2026-03-01 12:30: Decisi√≥n de usar producci√≥n para benchmarks

---

## üîß Fixes Aplicados

### Fix #1: Migrar juez a Groq (2026-02-27)
- Modificar `scripts/evaluate-accuracy.mjs` para soportar `JUDGE_PROVIDER=groq`
- Actualizar `.env.example` con configuraci√≥n recomendada
- Documentar en README.md

### Fix #2: Auto-detect Xenova Provider (2026-03-01)
- Detectar autom√°ticamente `EMB_PROVIDER=xenova` cuando modelo empieza con `Xenova/`
- Previene errores 404 en producci√≥n
- Backward compatible con configuraci√≥n expl√≠cita

### Fix #3: JUDGE_MODEL 14b ‚Üí 7b (2026-03-01)
- Reducir consumo RAM del juez de 9.8GB ‚Üí ~4GB
- Permite benchmarks locales (aunque lentos)
- Trade-off: ligeramente menos preciso pero funcional

