# ü§ñ TAREAS OPENCLAW ‚Äî ColLawRAG
**Generado:** 2026-02-16  
**Estas tareas las ejecuta OpenClaw de forma aut√≥noma o cuando Le'saint lo pida**

---

## ‚ö° TAREAS INMEDIATAS (ejecutar hoy)

---

### OC-A1 ‚Äî Ejecutar benchmark de accuracy BASELINE

**Cu√°ndo:** Ahora (antes de cualquier cambio de Cursor)  
**Por qu√©:** Necesitamos medir el accuracy actual (estimado 60‚Äì70%) para saber cu√°nto mejora cada fix.

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG

# Opci√≥n 1: script existente
node scripts/evaluate-accuracy.mjs 2>&1 | tee data/benchmarks/baseline-2026-02-16.log

# Opci√≥n 2: si el script no funciona, hacer manualmente con curl
# Para cada pregunta del benchmark QA (data/benchmarks/qa-abogados.json),
# llamar a la API y comparar con respuesta_referencia
```

**Output esperado:** `data/benchmarks/baseline-YYYY-MM-DD.json` con % accuracy por √°rea.

**Notificar a Le'saint:** El % de accuracy por √°rea (laboral, constitucional, etc.)

---

### OC-A2 ‚Äî Hacer re-ingesta DESPU√âS de que Cursor complete CU-01 + CU-02

**Trigger:** Cuando Cursor confirme que termin√≥ los cambios en `ingest.mjs`

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG
npm run ingest
npm run build-bm25
```

**Verificar:** Revisar el nuevo `data/index.json` y confirmar que los chunks tienen `metadata.area` diferente a 'general' (debe bajar de 99.7% a <30%).

```bash
# Contar chunks con area != 'general'
node -e "
const idx = JSON.parse(require('fs').readFileSync('data/index.json','utf8'));
const total = idx.length;
const conArea = idx.filter(c => c.metadata?.area && c.metadata.area !== 'general' && c.metadata.area !== 'unknown').length;
console.log('Total chunks:', total);
console.log('Con area espec√≠fica:', conArea, '(' + (conArea/total*100).toFixed(1) + '%)');
const areas = {};
idx.forEach(c => { const a = c.metadata?.area || 'unknown'; areas[a] = (areas[a]||0)+1; });
console.log('Distribuci√≥n:', JSON.stringify(areas, null, 2));
"
```

**Notificar:** Total chunks, distribuci√≥n por √°rea, mejora vs baseline.

---

### OC-A3 ‚Äî Re-ejecutar benchmark DESPU√âS de CU-01 + CU-02 + re-ingesta

**Trigger:** Despu√©s de OC-A2

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG
node scripts/evaluate-accuracy.mjs 2>&1 | tee data/benchmarks/post-fix-$(date +%Y-%m-%d).log
```

**Notificar a Le'saint:** Diferencia de accuracy antes/despu√©s del fix.

---

### OC-A4 ‚Äî Subir √≠ndices actualizados a GitHub Releases

**Trigger:** Despu√©s de OC-A2 (re-ingesta exitosa)

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG
npm run upload-indices
```

**Luego verificar en Vercel (si ya est√° configurado):**
```bash
# Trigger re-deploy
npx vercel --prod
```

---

## üìÖ TAREAS PERI√ìDICAS (cron jobs ya configurados)

---

### OC-B1 ‚Äî Monitoreo diario (autom√°tico, 9:05 AM)
**Ya configurado como cron job.**

Verifica: health check + queries de prueba + tiempo de respuesta.  
Alerta si: respuesta >8s, error en health, citas = 0.

---

### OC-B2 ‚Äî Warm-up Vercel (autom√°tico, 7am/1pm/7pm)
**Ya configurado como cron job.**

Previene cold starts llamando a `/api/health` cada 8 horas.

---

### OC-B3 ‚Äî Reporte semanal (autom√°tico, lunes 8 AM)
**Ya configurado como cron job.**

Revisa: calidad de respuestas, avance del roadmap, pr√≥ximos pasos.

---

## üîß TAREAS BAJO DEMANDA (cuando Le'saint lo pida)

---

### OC-C1 ‚Äî Scraping de jurisprudencia nueva

**Cu√°ndo usar:** Para aumentar cobertura de sentencias (actualmente ~600 sentencias)

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG

# Tutellas 2025
node scripts/scrape-jurisprudencia.mjs --year=2025 --type=tutela

# Constitucionalidad 2024-2025
node scripts/scrape-jurisprudencia.mjs --year=2024 --type=constitucionalidad
node scripts/scrape-jurisprudencia.mjs --year=2025 --type=constitucionalidad

# Sentencias de Unificaci√≥n
node scripts/scrape-jurisprudencia.mjs --year=2024 --type=unificacion
node scripts/scrape-jurisprudencia.mjs --year=2025 --type=unificacion
```

**Nota:** El sitio de la Corte Constitucional puede devolver HTTP 403 por anti-bot. En ese caso, reportar a Le'saint para descarga manual.

---

### OC-C2 ‚Äî Generar benchmark expandido (100 casos)

**Cu√°ndo usar:** Para tener evaluaci√≥n m√°s robusta de accuracy

**Tarea:** Crear 80 preguntas adicionales al archivo `data/benchmarks/qa-abogados.json` (que ya tiene 20 casos) bas√°ndose en los documentos del corpus.

**Distribuci√≥n objetivo:**
- Laboral: 25 preguntas (cesant√≠as, vacaciones, despido, horas extras, jornada)
- Constitucional: 20 preguntas (tutela, derechos fundamentales, jurisprudencia)
- Administrativo: 15 preguntas (derecho de petici√≥n, nulidad, contencioso)
- Civil: 15 preguntas (contratos, familia, propiedad)
- Penal: 10 preguntas (delitos, proceso penal)
- Tributario: 15 preguntas (renta, IVA, retenci√≥n)

**Formato a mantener:**
```json
{
  "id": "LAB-XXX",
  "area": "laboral",
  "dificultad": "basico|intermedio|avanzado",
  "pregunta": "...",
  "respuesta_referencia": "...",
  "normas_clave": ["Art. X CST", "Ley Y"],
  "criterio_evaluacion": "..."
}
```

**Generar usando** los documentos en `data/documents/` como fuente de verdad.

---

### OC-C3 ‚Äî An√°lisis de cobertura de corpus

**Cu√°ndo usar:** Para saber qu√© normas faltan en el √≠ndice

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG

# Listar qu√© normas de scrape-meta EST√ÅN en documents/
ls data/documents/ | sort > /tmp/docs-actual.txt
ls data/scrape-meta/ | sed 's/\.json$//' | sort > /tmp/docs-meta.txt

# Ver cu√°les tienen archivo en scrape-meta pero no en documents
comm -23 /tmp/docs-meta.txt /tmp/docs-actual.txt

# Ver distribuci√≥n de chunks por √°rea en el √≠ndice actual
node -e "
const idx = JSON.parse(require('fs').readFileSync('data/index.json','utf8'));
const areas = {};
const tipos = {};
idx.forEach(c => {
  const a = c.metadata?.area || c.metadata?.areaLegal || 'unknown';
  const t = c.metadata?.type || 'unknown';
  areas[a] = (areas[a]||0)+1;
  tipos[t] = (tipos[t]||0)+1;
});
console.log('=== Por √°rea ===');
Object.entries(areas).sort((a,b)=>b[1]-a[1]).forEach(([k,v]) => 
  console.log(k + ': ' + v + ' (' + (v/idx.length*100).toFixed(1) + '%)')
);
console.log('=== Por tipo ===');
Object.entries(tipos).sort((a,b)=>b[1]-a[1]).forEach(([k,v]) => 
  console.log(k + ': ' + v + ' (' + (v/idx.length*100).toFixed(1) + '%)')
);
"
```

**Reportar:** Lista de normas faltantes y chunks por √°rea.

---

### OC-C4 ‚Äî Verificar vigencia de normas del corpus

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG
node scripts/vigencia-normas.mjs 2>&1 | head -50
```

**Reportar:** Normas posiblemente desactualizadas para actualizaci√≥n manual.

---

### OC-C5 ‚Äî Generar documentos de compliance LPDP

**Cu√°ndo usar:** Antes del lanzamiento comercial

**Tarea:** Generar borradores de:

1. **`docs/legal/politica-datos-personales.md`**  
   Pol√≠tica de Tratamiento de Datos Personales seg√∫n Ley 1581/2012 y Decreto 1377/2013.
   Incluir: responsable del tratamiento, finalidades, derechos del titular, procedimientos.

2. **`docs/legal/terminos-servicio.md`**  
   T√©rminos de servicio espec√≠ficos para plataforma de asesor√≠a legal con IA.
   Incluir: naturaleza del servicio (informativo, no vinculante), limitaciones de responsabilidad, propiedad intelectual.

3. **`docs/legal/aviso-privacidad.md`**  
   Aviso simplificado para mostrar a usuarios en el registro.

---

### OC-C6 ‚Äî Analizar queries reales de producci√≥n

**Cu√°ndo usar:** Una vez que haya usuarios reales haciendo consultas

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG

# Si hay SQLite local con datos:
node -e "
const db = require('better-sqlite3')('data/users.db');
try {
  const queries = db.prepare('SELECT query, legal_area, COUNT(*) as count FROM queries GROUP BY legal_area ORDER BY count DESC').all();
  console.log('Queries por √°rea:');
  queries.forEach(q => console.log(q.legal_area + ': ' + q.count));
  
  const failures = db.prepare('SELECT query, response_time FROM queries WHERE success=0 ORDER BY created_at DESC LIMIT 20').all();
  console.log('\\n√öltimas queries fallidas:');
  failures.forEach(q => console.log(q.query.slice(0,80)));
} catch(e) { console.log('BD no disponible:', e.message); }
"
```

**Reportar:** Top √°reas consultadas, queries sin respuesta √∫til, patrones de fallo.

---

### OC-C7 ‚Äî Test de queries complejas

**Cu√°ndo usar:** Despu√©s de cualquier re-ingesta o cambio de prompts

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG
node scripts/test-complex-queries.mjs 2>&1
```

---

### OC-C8 ‚Äî Generar reporte de calidad manual

```bash
cd /home/lesaint/Documentos/Cursor/ColLawRAG
node scripts/generate-quality-report.mjs 2>&1
```

---

## üìä M√âTRICAS QUE OPENCLAW DEBE RASTREAR

Para cada reporte, incluir estas m√©tricas:

| M√©trica | C√≥mo medir | Objetivo |
|---|---|---|
| Accuracy benchmark | `evaluate-accuracy.mjs` | >85% (Sprint 1), >90% (Sprint 4) |
| % chunks con area espec√≠fica | Script node inline | >70% |
| Total chunks | `index.json` length | >15,000 |
| Cold start time | Medir primer request | <5s |
| P95 response time | Logs de monitoreo | <6s |
| Uptime producci√≥n | Health check diario | >99% |

---

## üö¶ FLUJO DE TRABAJO CON CURSOR

```
Cursor hace CU-01 (ingest.mjs)
    ‚Üì
Cursor hace CU-02 (chunk size)
    ‚Üì
Cursor confirma "listo para re-ingestar"
    ‚Üì
OpenClaw: OC-A2 (npm run ingest)
    ‚Üì
OpenClaw: verificar distribuci√≥n de metadata
    ‚Üì
OpenClaw: OC-A3 (benchmark post-fix)
    ‚Üì
OpenClaw: OC-A4 (upload-indices)
    ‚Üì
OpenClaw: notificar a Le'saint con resultados

Si accuracy mejor√≥ >10%:
    ‚Üí Cursor puede proceder con CU-03 (Postgres)
Si accuracy NO mejor√≥:
    ‚Üí Reportar a Le'saint para investigar
```

---

## üìÅ ARCHIVOS DE REFERENCIA

| Archivo | Descripci√≥n |
|---|---|
| `DIAGNOSTICO_COMERCIAL_2026-02-16.md` | Diagn√≥stico completo con roadmap |
| `TAREAS_CURSOR.md` | Tareas de c√≥digo para Cursor |
| `data/benchmarks/qa-abogados.json` | 20 casos QA para medir accuracy |
| `scripts/evaluate-accuracy.mjs` | Script de evaluaci√≥n de accuracy |
| `data/benchmarks/` | Guardar aqu√≠ todos los resultados |

---

*Actualizar con ‚úÖ/‚ùå y fecha cuando se complete cada tarea*
